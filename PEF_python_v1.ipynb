{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Streaming prediction-error filters\n",
        "\n",
        "Prediction-error filters (PEFs) are essential in seismic deconvolution and other geophysical estimation problems. We show that non-stationary multidimensional PEFs can be computed in a \"streaming\" manner, where the filter gets updated incrementally by accepting one new data point at a time. The computational cost of estimating a streaming PEF reduces to the cost of a single convolution. In other words, the cost of PEF design while filtering equals the cost of applying the filter. Moreover, the non-linear operation of finding and applying a streaming PEF is invertible at a similar cost, which enables a fast approach to missing data interpolation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Introduction\n",
        "\n",
        "Prediction-error filters (PEFs) play an essential role in geophysical data analysis. They can be used directly in different forms of seismic deconvolution (Webster, 1978; Robinson & Osman, 1996). More importantly, PEFs are a practical approximation for covariance operators used in geophysical estimation problems (Claerbout, 2014). As such, they provide a way to absorb and characterize statistical patterns in a given dataset (Claerbout & Brown, 1999).\n",
        "\n",
        "Because most natural patterns are non-stationary, extending the classic stationary formulation to non-stationarity is vital. This extension can be done either by \"patching\" or breaking data into overlapping windows or by a smoothly non-stationary estimation with regularization (Crawley et al., 1999; Curry, 2003). Shaping regularization provides a particularly effective method for constraining the filter variability (Fomel, 2009; Liu & Fomel, 2011; Liu et al., 2012). Both approaches have an additional computational expense, particularly in storing variable filter coefficients (Ruan et al., 2015).\n",
        "\n",
        "This paper presents an efficient approach to computing and applying non-stationary PEFs with no excessive storage requirements. Using an adaptive-filtering approach (Widrow \\& Stearns, 1985; Haykin, 2002), We show that a non-stationary PEF can be updated on the fly by accepting one data point at a time. The cost of computing and applying such a PEF reduces to the cost of a single convolution. In other words, the cost of PEF design while filtering equals the cost of applying the filter. Moreover, the non-linear operation of finding and applying a PEF has an exact inverse, which finds an immediate application in missing data interpolation problems. We extend the\n",
        "filter from 1-D to multiple dimensions using the helix transform (Claerbout, 1998) and show its application to simple benchmark problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Theory       \n",
        "\n",
        "The basic equation defining a prediction-error filter is auto-regression. For a given data stream $\\mathbf{d}$ and a one-dimensional PEF $\\mathbf{a}$, the auto-regression equation takes the form\n",
        "\n",
        "$$\\left[\\begin{array}{ccccc} d_{n+1} & d_n & d_{n-1} & \\cdots &\n",
        "                                                   d_{n+1-k} \\end{array}\\right]\\,\n",
        "\\left[\\begin{array}{l} 1 \\\\ a_1 \\\\ a_2 \\\\ \\cdots \\\\ a_k \\end{array}\\right]\n",
        "\\approx 0\\;,$$\n",
        "\n",
        "where it is assumed that $n \\ge k$. Equation 1 represents the convolution of the data with the prediction-error filter.\n",
        "\n",
        "Suppose the filter gets updated with each new data point\n",
        "$d_{n+1}$. The additional constraint we can impose to control\n",
        "the variability of the filter is that the new filter $a$ stays close\n",
        "to the previous filter $\\bar{a}$.\n",
        "\n",
        "The two conditions can be combined into one overdetermined linear system\n",
        "\n",
        "$$\\left[\\begin{array}{cccc} d_n & d_{n-1} & \\cdots & d_{n+1-k} \\\\\n",
        "      \\lambda & 0 & & 0 \\\\\n",
        "      0 & \\lambda & & 0 \\\\\n",
        "    \\cdots & \\cdots & & \\cdots \\\\\n",
        "      0 & 0 & \\cdots & \\lambda\n",
        "    \\end{array}\\right]\\,\n",
        "  \\left[\\begin{array}{l} a_1 \\\\ a_2 \\\\ \\cdots \\\\ a_k \\end{array}\\right] \\approx\n",
        "  \\left[\\begin{array}{l} - d_{n+1} \\\\\n",
        "      \\lambda\\,\\bar{a}_1 \\\\\n",
        "      \\lambda\\,\\bar{a}_2 \\\\\n",
        "     \\cdots \\\\\n",
        "      \\lambda\\,\\bar{a}_k\n",
        "    \\end{array}\\right]\\;,$$\n",
        "\n",
        "where $\\lambda$ is the parameter that controls how much we allow \n",
        "$a$ to deviate from $\\bar{a}$. In a shortened block-matrix notation, we can rewrite the linear system of equations as\n",
        "\n",
        "$$\\left[\\begin{array}{c} \\mathbf{d}^T \\\\ \\lambda\\,\\mathbf{I} \\end{array}\\right]\\,\\mathbf{a} \\approx\n",
        "  \\left[\\begin{array}{l} - d_{n+1} \\\\\n",
        "      \\lambda\\,\\bar{\\mathbf{a}} \n",
        "    \\end{array}\\right]\\;,$$\n",
        "    \n",
        "where\n",
        "\n",
        "$$\\mathbf{d} = \\left[\\begin{array}{l} d_n \\\\ d_{n-1} \\\\ \\cdots \\\\ d_{n+1-k} \\end{array}\\right]\\;, \\quad\n",
        "\\mathbf{a} = \\left[\\begin{array}{l} a_1 \\\\ a_2 \\\\ \\cdots \\\\ a_k \\end{array}\\right]\\;,$$\n",
        "\n",
        "and $\\mathbf{I}$ is the identity matrix. \n",
        "\n",
        "The least-squares solution of the overdetermined system is\n",
        "\n",
        "$$\\mathbf{a} = \\left(\\mathbf{d}\\,\\mathbf{d}^T + \\lambda^2\\,\\mathbf{I}\\right)^{-1}\\,\n",
        "  \\left(-d_{n+1}\\,\\mathbf{d} + \\lambda^2\\,\\bar{\\mathbf{a}}\\right)\\;.$$\n",
        "\n",
        "Next, we can use the Sherman-Morrison formula from linear algebra\n",
        "(Hager, 1989) to transform the inverse matrix as follows:\n",
        "\n",
        "$$\\left(\\mathbf{d}\\,\\mathbf{d}^T + \\lambda^2\\,\\mathbf{I}\\right)^{-1} =\n",
        "  \\frac{1}{\\lambda^2}\\,\\left(\\mathbf{I} - \\frac{\\mathbf{d}\\,\\mathbf{d}^T}{\\lambda^2+\\mathbf{d}^T\\,\\mathbf{d}}\\right)\\;.$$\n",
        "\n",
        "Substituting the Sherman-Morrison equation and doing\n",
        "algebraic simplifications lead to the final result:\n",
        "\n",
        "$$\\begin{array}{rcl}\\mathbf{a} & = & \\displaystyle \\frac{1}{\\lambda^2}\\,\\left(\\mathbf{I} -\n",
        "                   \\frac{\\mathbf{d}\\,\\mathbf{d}^T}{\\lambda^2+\\mathbf{d}^T\\,\\mathbf{d}}\\right)\\,\\left(-d_{n+1}\\,\\mathbf{d}\n",
        "                   + \\lambda^2\\,\\bar{\\mathbf{a}}\\right) \\\\\n",
        "& = &\n",
        "\\displaystyle \\bar{\\mathbf{a}} -\n",
        "  \\left(\\frac{d_{n+1}+\\mathbf{d}^T\\,\\bar{\\mathbf{a}}}{\\lambda^2+\\mathbf{d}^T\\,\\mathbf{d}}\\right)\\,\\mathbf{d}\\;.\\end{array}$$\n",
        "  \n",
        "The Sherman-Morrison technique is a well-known approach in adaptive filtering by recursive least-squares (Haykin, 2002).\n",
        "  \n",
        "This equation shows that the filter is updated by subtracting\n",
        "a scaled version of the data. The scale is proportional to the\n",
        "convolution residual computed using the previous version of the\n",
        "filter. Updating the filter requires only elementary algebraic operations (vector dot products) and no iterations. Moreover, computing the dot product\n",
        "$\\mathbf{d}^T\\,\\mathbf{d}$ in a \"streaming\" fashion requires at most\n",
        "two multiplications:\n",
        "\n",
        "$$\\mathbf{d}^T\\,\\mathbf{d} = \\bar{\\mathbf{d}}^T\\,\\bar{\\mathbf{d}} +\n",
        "d_n^2 - d_{n-k}^2\\;,$$\n",
        "\n",
        "where $k$ is number of points in $\\mathbf{a}$ and $\\mathbf{d}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inversion\n",
        "\n",
        "The streaming residual $r_{n+1}$ from the left-hand side of\n",
        "equation 1 can be expressed as\n",
        "\n",
        "$$r_{n+1} = d_{n+1} + \\mathbf{d}^T\\,\\mathbf{a}$$\n",
        "\n",
        "or, substituting equation for $\\mathbf{a}$,\n",
        "\n",
        "$$\\begin{array}{rcl}r_{n+1} & = & \\displaystyle d_{n+1} + \\mathbf{d}^T\\,\\left[\\bar{\\mathbf{a}} -\n",
        "              \\left(\\frac{d_{n+1}+\\mathbf{d}^T\\,\\bar{\\mathbf{a}}}{\\lambda^2+\\mathbf{d}^T\\,\\mathbf{d}}\\right)\\,\\mathbf{d}\\right]\n",
        "  \\\\\n",
        "\\nonumber\n",
        "& = & \\displaystyle \\left(d_{n+1} +\n",
        "      \\mathbf{d}^T\\,\\bar{\\mathbf{a}}\\right)\\,\\left(1-\\frac{\\mathbf{d}^T\\,\\mathbf{d}}{\\lambda^2+\\mathbf{d}^T\\,\\mathbf{d}}\\right)\n",
        "  \\\\\n",
        "& = & \\displaystyle \\frac{\\lambda^2\\,\\left(d_{n+1} +\n",
        "  \\mathbf{d}^T\\,\\bar{\\mathbf{a}}\\right)}{\\lambda^2+\\mathbf{d}^T\\,\\mathbf{d}}\\;.\\end{array}$$\n",
        "\n",
        "\n",
        "The equation for $r_{n+1}$ can be directly inverted to reconstruct~$d_{n+1}$ as follows:\n",
        "\n",
        "$$d_{n+1} = r_{n+1}\\,\\left(1+\\frac{\\mathbf{d}^T\\,\\mathbf{d}}{\\lambda^2}\\right) - \\mathbf{d}^T\\,\\bar{\\mathbf{a}}\\;.$$\n",
        "\n",
        "We see that streaming time-variable deconvolution is invertible: both the input data and the time-varying filter can be reconstructed from the streaming residual. Note that because of the division by $\\lambda^2$, the inverse operation may become numerically unstable for small $\\lambda$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "J5Upq2a_91hL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "n1 = 400\n",
        "\n",
        "# exponentially decaying sinusoids with different frequencies\n",
        "inp = np.zeros(n1, dtype=np.float32)\n",
        "for j in range((n1 // 15), n1, n1 // 5):\n",
        "    wave = np.zeros(n1, dtype=np.float32)\n",
        "    for x in range(j, 399+1):\n",
        "        y = (x - j) / 400\n",
        "        wave[x-1] = np.exp(-y * 15) * np.sin(y * 0.95 * j)\n",
        "    inp += wave\n",
        "\n",
        "res = np.copy(inp)\n",
        "bak = np.copy(inp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "w28VUArT-GWT"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "H7ahCZ7n-GZy"
      },
      "outputs": [],
      "source": [
        "def stems(data, label, color):\n",
        "    n1 = len(data)\n",
        "\n",
        "    # Create a plot with initial zeros\n",
        "    plt.plot(np.zeros(n1), label=None, color='black')\n",
        "\n",
        "    # Create a stem plot\n",
        "    plt.stem(data, label=label, linefmt=color, markerfmt=' ', basefmt=\" \")\n",
        "\n",
        "    # Add legend and formatting\n",
        "    plt.legend(loc='upper left')\n",
        "    plt.xlim([0.5, n1 + 0.5])\n",
        "    plt.gca().spines['top'].set_visible(False)\n",
        "    plt.gca().spines['right'].set_visible(False)\n",
        "    plt.gca().spines['left'].set_visible(False)\n",
        "    plt.gca().spines['bottom'].set_visible(False)\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "I0e21CS4-Gby"
      },
      "outputs": [],
      "source": [
        "def stems(data, label, color):\n",
        "    n1 = len(data)\n",
        "\n",
        "    # Create a plot with initial zeros\n",
        "    plt.plot(np.zeros(n1), label=None, color='black')\n",
        "\n",
        "    # Create a stem plot\n",
        "    # plt.stem(data, label=label, linefmt=color, markerfmt=' ', basefmt=\" \", use_line_collection=True)\n",
        "    plt.stem(data, label=label, linefmt=color, markerfmt=' ', basefmt=\" \")\n",
        "\n",
        "    # Add legend and formatting\n",
        "    plt.legend(loc='upper left')\n",
        "    plt.xlim([0.5, n1 + 0.5])\n",
        "    plt.gca().spines['top'].set_visible(False)\n",
        "    plt.gca().spines['right'].set_visible(False)\n",
        "    plt.gca().spines['left'].set_visible(False)\n",
        "    plt.gca().spines['bottom'].set_visible(False)\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "6B9a0bgG-Gdx",
        "outputId": "4e82f648-18b7-430a-bafd-eca8bfe8fcc9"
      },
      "outputs": [],
      "source": [
        "plot_input = stems(inp, \"input\", \"blue\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "jeGOTzPA-Gfx"
      },
      "outputs": [],
      "source": [
        "def stream(inv, d, r, na, lambd):\n",
        "\n",
        "    a = np.zeros(na,dtype=np.float32)  # streaming PEF\n",
        "    dd = da = 0.0  # d (dot) d, d (dot) a\n",
        "\n",
        "    for ia in range(na):\n",
        "        if inv:\n",
        "            d[ia] = r[ia]\n",
        "        else:\n",
        "            r[ia] = d[ia]\n",
        "        dd += d[ia] * d[ia]\n",
        "\n",
        "    rn = np.float64(\"0.\")\n",
        "    for i1 in range(na, n1):\n",
        "        if inv:  # from r to d\n",
        "            rn = r[i1] / lambd\n",
        "            # rn = np.divide(r[i1], lambd,dtype=np.float64)\n",
        "            dn = rn * (lambd + dd) - da\n",
        "            d[i1] = dn\n",
        "        else:  # from d to r\n",
        "            dn = d[i1]\n",
        "            # rn = (dn + da) / (lambd + dd)\n",
        "            rn = np.divide(np.add(dn, da, dtype=np.float64), np.add(lambd, dd,dtype=np.float64),dtype=np.float64)\n",
        "            r[i1] = lambd * rn\n",
        "\n",
        "        # update PEF\n",
        "        for ia in range(na):\n",
        "            a[ia] -= rn * d[i1 - ia - 1]\n",
        "\n",
        "        # update dd and da\n",
        "        dd += dn * dn - d[i1 - na] * d[i1 - na]\n",
        "        da = dn * a[0]\n",
        "        for ia in range(1, na):\n",
        "            da += a[ia] * d[i1 - ia]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0nttBhkN-GlJ",
        "outputId": "27338da6-ebaf-4881-cc98-d82129c6d627"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create subplots with a layout of 3 rows and 1 column\n",
        "fig, axs = plt.subplots(3, 1, figsize=(8, 12))  # Adjust figsize as needed\n",
        "\n",
        "# Plot the input data\n",
        "axs[0].stem(inp, linefmt='blue', markerfmt=' ', basefmt=\" \")\n",
        "axs[0].set_title(\"Input\")\n",
        "axs[0].set_xlim([0.5, len(inp) + 0.5])\n",
        "axs[0].legend([\"Input\"], loc='upper left')\n",
        "axs[0].spines['top'].set_visible(False)\n",
        "axs[0].spines['right'].set_visible(False)\n",
        "axs[0].spines['left'].set_visible(False)\n",
        "axs[0].spines['bottom'].set_visible(False)\n",
        "\n",
        "# Plot the decon data\n",
        "stream(False,inp,res,2,0.1)\n",
        "axs[1].stem(res, linefmt='green', markerfmt=' ', basefmt=\" \")\n",
        "axs[1].set_title(\"Decon\")\n",
        "axs[1].set_xlim([0.5, len(res) + 0.5])\n",
        "axs[1].legend([\"Decon\"], loc='upper left')\n",
        "axs[1].spines['top'].set_visible(False)\n",
        "axs[1].spines['right'].set_visible(False)\n",
        "axs[1].spines['left'].set_visible(False)\n",
        "axs[1].spines['bottom'].set_visible(False)\n",
        "\n",
        "# Plot the inverse data\n",
        "stream(True,bak,res,2,0.1)\n",
        "axs[2].stem(bak, linefmt='purple', markerfmt=' ', basefmt=\" \")\n",
        "axs[2].set_title(\"Inverse\")\n",
        "axs[2].set_xlim([0.5, len(bak) + 0.5])\n",
        "axs[2].legend([\"Inverse\"], loc='upper left')\n",
        "axs[2].spines['top'].set_visible(False)\n",
        "axs[2].spines['right'].set_visible(False)\n",
        "axs[2].spines['left'].set_visible(False)\n",
        "axs[2].spines['bottom'].set_visible(False)\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plots\n",
        "plt.show()\n",
        "\n",
        "plt.savefig(\"stream.pdf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Eymj4oMn-GnC",
        "outputId": "047a8c32-7a12-4804-a9c8-c7265c220353"
      },
      "outputs": [],
      "source": [
        "plt.savefig(\"stream.pdf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Multiple dimensions\n",
        "\n",
        "In order to extend the filter from 1-D to multiple dimensions, we follow the\n",
        "helix transform of Claerbout (1998). The change is minimal:\n",
        "the multidimensional data is arranged in a 1D stream on a helix, and\n",
        "the definition of the data vector $\\mathbf{d}$ changes to\n",
        "\n",
        "$$\\mathbf{d} = \\left[\\begin{array}{l} d_{n+1-l_1} \\\\ d_{n+1-l_2} \\\\ \\cdots \\\\ d_{n+1-l_k} \\end{array}\\right]$$\n",
        "\n",
        "where $l_1, l_2, \\ldots, l_k$ represent lags of the helical filter. The computational cost and other benefits of streaming PEFs remain the same.\n",
        "\n",
        "One caveat is that, in multiple dimensions, we may want the\n",
        "nonstationary filter to change smoothly along the helix and other dimensions. As shown below, this goal can be accomplished with only a minor change to the algorithm. Suppose that $\\bar{\\mathbf{a}}_1$ is the previous filter in the first (helical) dimension, and $\\bar{\\mathbf{a}}_2$ is the previous filter in the second dimension. We can keep the newly estimated streaming PEF close to both\n",
        "filters by changing the matrix equation to\n",
        "\n",
        "$$\\left[\\begin{array}{c} \\mathbf{d}^T \\\\ \\lambda_1\\,\\mathbf{I} \\\\  \\lambda_2\\,\\mathbf{I}  \\end{array}\\right]\\,\\mathbf{a} \\approx\n",
        "  \\left[\\begin{array}{l} - d_{n+1} \\\\\n",
        "      \\lambda_1\\,\\bar{\\mathbf{a}}_1 \\\\ \\lambda_2\\,\\bar{\\mathbf{a}}_2\n",
        "    \\end{array}\\right]\\;,$$\n",
        "\n",
        "where $\\lambda_1$ and $\\lambda_2$ control the filter variability in the two directions. The least-squares solution of this system is\n",
        "\n",
        "$$\\mathbf{a} = \\left(\\mathbf{d}\\,\\mathbf{d}^T + \\lambda^2\\,\\mathbf{I}\\right)^{-1}\\,\n",
        "  \\left(-d_{n+1}\\,\\mathbf{d} + \\lambda_1^2\\,\\bar{\\mathbf{a}}_1 +\n",
        "    \\lambda_1^2\\,\\bar{\\mathbf{a}}_2 \\right)\\;,$$\n",
        "\n",
        "where $\\lambda^2 = \\lambda_1^2+\\lambda_2^2$. The new equation\n",
        "is equivalent to the previous equation with the simple substitution\n",
        "\n",
        "$$\\bar{\\mathbf{a}} = \\displaystyle \\frac{\\lambda_1^2\\,\\bar{\\mathbf{a}}_1 +\n",
        "    \\lambda_2^2\\,\\bar{\\mathbf{a}}_2}{\\lambda_1^2+\\lambda_2^2}\\;.$$\n",
        "\n",
        "Thus, the only change in the algorithm is an increase in the storage to keep track of both $\\bar{\\mathbf{a}}_1$ and $\\bar{\\mathbf{a}}_2$. The extension to more dimensions is analogous."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cost comparison\n",
        "\n",
        "Table 1 compares the computational cost of different approaches to computing prediction-error filters. The cost of streaming PEF is minimal and reduces to the cost of a single convolution. Streaming PEF can capture the input data's non-stationary character without storing multiple copies of the filter.\n",
        "\n",
        "Moreover, all streaming computations are local, which makes them\n",
        "particularly suitable for modern hardware accelerators such as\n",
        "GPGPU (Sanders & Kandrot, 2010) or Intel Xeon Phi (Jeffers & Reinders, 2013).\n",
        "\n",
        "| Method | Storage | Cost |\n",
        "|:-------|:--------|:-----|\n",
        "| Stationary PEF | $O(N_a)$ | $O(N_a^2\\,N_d)$ |\n",
        "| Non-stationary PEF | $O(N_a\\,N_d)$ | $ O(N_a^2\\,N_d)$ |\n",
        "| Streaming PEF | $O(N_a)$ | $O(N_a\\,N_d)$ |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Missing data interpolation\n",
        "\n",
        "The existence of the exact inversion for the application of a streaming PEF allows for a straightforward approach to missing data interpolation. When reading data in a streaming fashion, every time we meet a missing data point $d_{n+1}$, we can replace its value by a\n",
        "value computed from the residual. The residual value $r_{n+1}$ in this case can be set to zero or to a random number (white noise) with the expected variance of the residual. In the latter case, it is possible to generate multiple equiprobable distributions for the interpolation\n",
        "result (Clapp, 2000)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "_4g00EyY-GpC"
      },
      "outputs": [],
      "source": [
        "# Create a deepcopy of inp\n",
        "inp2 = np.copy(inp)\n",
        "known = np.ones(n1, dtype=bool)\n",
        "\n",
        "# Cut holes in the data and create a mask\n",
        "holes = [55, 153, 246, 301, 376]\n",
        "for hole in holes:\n",
        "    inp2[hole:hole + 20] = 0  # Note: Python slicing is exclusive of the end index\n",
        "    known[hole:hole + 20] = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "00eYGB2D-Gq6"
      },
      "outputs": [],
      "source": [
        "def stream_missing(d, k, na, lambd):\n",
        "\n",
        "    a = np.zeros(na)  # streaming PEF\n",
        "    da = 0.0  # d (dot) a\n",
        "    dd = 0.0  # d (dot) d\n",
        "\n",
        "    for ia in range(na):\n",
        "        dd += d[ia] * d[ia]\n",
        "\n",
        "    for i1 in range(na, len(d)):\n",
        "        if k[i1]:  # from d to r\n",
        "            dn = d[i1]\n",
        "            rn = (dn + da) / (lambd + dd)\n",
        "        else:  # assume r=0\n",
        "            dn = -da\n",
        "            rn = 0.0\n",
        "            d[i1] = dn\n",
        "\n",
        "        # update PEF\n",
        "        for ia in range(na):\n",
        "            a[ia] -= rn * d[i1 - ia - 1]\n",
        "\n",
        "        # update dd and da\n",
        "        dd += dn * dn - d[i1 - na] * d[i1 - na]\n",
        "        da = dn * a[0]\n",
        "        for ia in range(1, na):\n",
        "            da += a[ia] * d[i1 - ia]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5a0Lkld3-Gyx",
        "outputId": "cbc9ff3c-15d7-4822-e4e3-08da7f917c63"
      },
      "outputs": [],
      "source": [
        "# Create subplots with a layout of 3 rows and 1 column\n",
        "fig, axs = plt.subplots(3, 1, figsize=(8, 12))  # Adjust figsize as needed\n",
        "\n",
        "# Plot the ideal data\n",
        "axs[0].stem(inp, linefmt='blue', markerfmt=' ', basefmt=\" \")\n",
        "axs[0].set_title(\"Ideal\")\n",
        "axs[0].set_xlim([0.5, len(inp) + 0.5])\n",
        "axs[0].legend([\"Ideal\"], loc='upper left')\n",
        "axs[0].spines['top'].set_visible(False)\n",
        "axs[0].spines['right'].set_visible(False)\n",
        "axs[0].spines['left'].set_visible(False)\n",
        "axs[0].spines['bottom'].set_visible(False)\n",
        "\n",
        "# Plot the input with holes\n",
        "axs[1].stem(inp2, linefmt='green', markerfmt=' ', basefmt=\" \")\n",
        "axs[1].set_title(\"Input with Holes\")\n",
        "axs[1].set_xlim([0.5, len(inp2) + 0.5])\n",
        "axs[1].legend([\"Input\"], loc='upper left')\n",
        "axs[1].spines['top'].set_visible(False)\n",
        "axs[1].spines['right'].set_visible(False)\n",
        "axs[1].spines['left'].set_visible(False)\n",
        "axs[1].spines['bottom'].set_visible(False)\n",
        "\n",
        "miss = np.copy(inp2,order='F')\n",
        "stream_missing(miss, known, 2, 0.05)\n",
        "# Plot the interpolated data\n",
        "axs[2].stem(miss, linefmt='purple', markerfmt=' ', basefmt=\" \")\n",
        "axs[2].set_title(\"Filled\")\n",
        "axs[2].set_xlim([0.5, len(miss) + 0.5])\n",
        "axs[2].legend([\"Filled\"], loc='upper left')\n",
        "axs[2].spines['top'].set_visible(False)\n",
        "axs[2].spines['right'].set_visible(False)\n",
        "axs[2].spines['left'].set_visible(False)\n",
        "axs[2].spines['bottom'].set_visible(False)\n",
        "\n",
        "f = plt.figure()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A simple 1D interpolation example using data from Figure 1 is shown in Figure 2. As evident from the figure, such interpolation, while capable of picking the non-stationary data pattern, remains one-sided and may create discontinuities at the other side of the data gap. We can rerun the streaming PEF using the opposite directions and stack the results to help with this issue."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "8BQ1OQU7-G0b"
      },
      "outputs": [],
      "source": [
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "hKMK_kJp-G2i"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import os\n",
        "\n",
        "# Download data from a public server\n",
        "url = \"https://zenodo.org/api/records/11099632/files-archive\"\n",
        "response = requests.get(url)\n",
        "with open(\"files.zip\", \"wb\") as file:\n",
        "    file.write(response.content)\n",
        "\n",
        "# Unzip the archive file\n",
        "with zipfile.ZipFile(\"files.zip\", \"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"extracted_folder\")  # Specify the directory to extract to\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "OSaPQgSz-G6s"
      },
      "outputs": [],
      "source": [
        "# Create a dictionary for easy access to files\n",
        "patterns = {}\n",
        "\n",
        "# Open the ZIP file and populate the dictionary\n",
        "with zipfile.ZipFile(\"files.zip\", \"r\") as zip_ref:\n",
        "    for file_info in zip_ref.infolist():\n",
        "        name = os.path.splitext(file_info.filename)[0]\n",
        "        patterns[name] = file_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "VmQof2dgF6a8"
      },
      "outputs": [],
      "source": [
        "# Create a dictionary for easy access to files\n",
        "patterns = {}\n",
        "\n",
        "# Open the ZIP file and populate the dictionary\n",
        "with zipfile.ZipFile(\"files.zip\", \"r\") as zip_ref:\n",
        "    for file_info in zip_ref.infolist():\n",
        "        name = os.path.splitext(file_info.filename)[0]\n",
        "        patterns[name] = file_info.filename\n",
        "\n",
        "# Example usage: access a specific file from the dictionary\n",
        "# To read the content of a file named \"wood\":\n",
        "with zipfile.ZipFile(\"files.zip\", \"r\") as zip_ref:\n",
        "    with zip_ref.open(patterns[\"wood\"]) as file:\n",
        "        # Read the file content (for example, as bytes)\n",
        "        data = file.read()\n",
        "        # Convert the data to an appropriate format, if necessary\n",
        "        # For example, you can convert it to a numpy array if it's numerical data\n",
        "        wood = np.frombuffer(data, dtype=np.float32).reshape(128, 128,order='F')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "6rALk-V8-G8i",
        "outputId": "94d2ef2b-ec90-436f-f10b-ef83e5f2ebc0"
      },
      "outputs": [],
      "source": [
        "plt.imshow(wood, cmap='inferno', interpolation='none', origin=\"lower\")\n",
        "plt.colorbar(label='Intensity')  \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "k_gIIpM5-HAa"
      },
      "outputs": [],
      "source": [
        "def punch_hole(data):\n",
        "\n",
        "    n1, n2 = data.shape\n",
        "    hole = np.zeros_like(data, dtype=np.float32, order='F')\n",
        "    mask = np.zeros((n1, n2), dtype=bool, order='F')\n",
        "\n",
        "    for i2 in range(n2):\n",
        "        for i1 in range(n1):\n",
        "            x = (i1) / n1 - 0.5\n",
        "            y = (i2) / n2 - 0.3\n",
        "            u = x + y\n",
        "            v = (x - y) / 2\n",
        "            if u*u + v*v < 0.15:\n",
        "                hole[i1, i2] = 0.0\n",
        "            else:\n",
        "                hole[i1, i2] = data[i1, i2]\n",
        "                mask[i1, i2] = True\n",
        "\n",
        "    return hole, mask\n",
        "\n",
        "# Example usage with `wood` array\n",
        "whole, wmask = punch_hole(wood)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4iZfZAIVpJV8"
      },
      "outputs": [],
      "source": [
        "plt.imshow(whole, cmap='inferno', interpolation='none', origin=\"lower\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBvlCPX3ruxU"
      },
      "outputs": [],
      "source": [
        "plt.imshow(wmask, cmap='inferno', interpolation='none', origin=\"lower\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "v_H2pQIyP57d"
      },
      "outputs": [],
      "source": [
        "def helix(lag, ci):\n",
        "\n",
        "    # Middle of the grid\n",
        "    mid = (np.array(ci) // 2) -1\n",
        "\n",
        "    # Helix index of middle\n",
        "    linear_indices_ci = np.arange(ci.prod()).reshape(tuple(ci), order='F')\n",
        "\n",
        "    hmid = linear_indices_ci[mid[0],mid[1]]\n",
        "\n",
        "    map = lag + mid\n",
        "\n",
        "    values = linear_indices_ci[map[:, 0], map[:, 1]] - hmid\n",
        "    return values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "NPC3-BP3iH_x"
      },
      "outputs": [],
      "source": [
        "from numba import njit\n",
        "import numpy as np\n",
        "\n",
        "# da changing\n",
        "# rn changing\n",
        "@njit\n",
        "def stream_missing_helix_core(na, d, k, hlag, λ, std, maxlag, n1):\n",
        "    # na = len(hlag)\n",
        "    a = np.zeros(na, dtype=np.float32)\n",
        "    da = 0.\n",
        "    dd = 0.\n",
        "\n",
        "    # Compute initial dd\n",
        "    # dd seems ok\n",
        "    for ia in range(na):\n",
        "        dd += d[maxlag - hlag[ia]] ** 2\n",
        "\n",
        "\n",
        "    for i1 in range(maxlag, n1):\n",
        "        if k[i1]:\n",
        "            dn = d[i1]\n",
        "\n",
        "            rn = (dn + da) / (λ + dd)\n",
        "\n",
        "        else:  # assume r_n is random\n",
        "            # rn = std * np.random.randn() / λ\n",
        "\n",
        "            myrandom = 0.26\n",
        "            rn = std * myrandom / λ\n",
        "\n",
        "            dn = rn * (λ + dd) - da\n",
        "            d[i1] = dn\n",
        "\n",
        "        # Update PEF\n",
        "        for ia in range(na):\n",
        "            if (i1 - hlag[ia]) >= 0:  # Ensure index is within bounds\n",
        "                a[ia] -= rn * d[i1 - hlag[ia]]\n",
        "\n",
        "        # Update dd and da\n",
        "        if (i1 - maxlag) >= 0:  # Ensure index is within bounds\n",
        "            dd += dn * dn - d[i1 - maxlag] * d[i1 - maxlag]\n",
        "        da = dn * a[0]\n",
        "        for ia in range(1, na):\n",
        "            if (i1 + 1 - hlag[ia]) >= 0:  # Ensure index is within bounds\n",
        "                da += a[ia] * d[i1 + 1 - hlag[ia]]\n",
        "\n",
        "def stream_missing_helix(d_n_dim, k_n_dim, lag, λ, std=0, seed=1):\n",
        "    \"Fill missing data in multiple dimensions using streaming PEF on a helix\"\n",
        "    d = np.reshape(d_n_dim, -1, order='F')\n",
        "    k = np.reshape(k_n_dim, -1, order='F')\n",
        "\n",
        "    n1, na = len(d), len(lag)\n",
        "    ci = np.array(d_n_dim.shape, order='F')\n",
        "    hlag = helix(lag, ci)\n",
        "    maxlag = np.max(hlag)\n",
        "    # np.random.seed(seed)\n",
        "\n",
        "    # Call the JIT-compiled core function\n",
        "    stream_missing_helix_core(na, d, k, hlag, λ, std, maxlag, n1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "collapsed": true,
        "id": "Py945a6D-HHx"
      },
      "outputs": [],
      "source": [
        "# 11 x 11 PEF\n",
        "lag = [(x, 0) for x in range(1, 6)]\n",
        "for k in range(1, 11):\n",
        "    lag.extend([(x, k) for x in range(-5, 6)])\n",
        "lag = np.array(lag)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "Eqvx34JZ-HJr"
      },
      "outputs": [],
      "source": [
        "def fill_hole(forward, hole, mask, pad, noise=0, seed=1):\n",
        "    \"Fill holes in data using forward or backward filling\"\n",
        "\n",
        "    if forward:\n",
        "        # Pad data with zeros on the left\n",
        "        holepad = np.hstack([np.zeros((hole.shape[0], pad), dtype=np.float32, order=\"F\"), hole])\n",
        "\n",
        "        maskpad = np.hstack([np.zeros((mask.shape[0], pad), dtype=bool, order=\"F\"), mask])\n",
        "\n",
        "        # Fill missing data\n",
        "        stream_missing_helix(holepad, maskpad, lag, 1e6, noise, seed)\n",
        "\n",
        "        # Return data without the padding\n",
        "        return holepad[:, pad:]\n",
        "\n",
        "    else:\n",
        "        # fake_randoms = rnd_seed2\n",
        "        # Reverse the data\n",
        "        rhole = np.asfortranarray(np.flip(hole))\n",
        "\n",
        "        rmask = np.asfortranarray(np.flip(mask))\n",
        "\n",
        "        # Pad reversed data with zeros on the left\n",
        "        holepad = np.hstack([np.zeros((rhole.shape[0], pad), dtype=np.float32, order=\"F\"), rhole])\n",
        "        maskpad = np.hstack([np.zeros((rmask.shape[0], pad), dtype=bool, order=\"F\"), rmask])\n",
        "\n",
        "        # Fill missing data\n",
        "        stream_missing_helix(holepad, maskpad, lag, 1e6, noise, seed + 1)\n",
        "\n",
        "        return np.asfortranarray(np.flip(holepad[:, pad:]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BOigcnY-HLq"
      },
      "outputs": [],
      "source": [
        "filled1 = fill_hole(True, whole, wmask, 20)\n",
        "filled2 = fill_hole(False, whole, wmask, 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "3152AjfDI_6M"
      },
      "outputs": [],
      "source": [
        "def plot2(ax, data, title):\n",
        "    # Display heatmap on the provided axis\n",
        "    im = ax.imshow(data, cmap='gray', vmin=-137, vmax=137)\n",
        "    ax.set_title(title)\n",
        "    return im "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzg8_NVsI_-M"
      },
      "outputs": [],
      "source": [
        "# Create the figure and subplots\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# Plot the three images\n",
        "im1 = plot2(ax1, filled1, \"(a) Filled 1\")\n",
        "im2 = plot2(ax2, filled2, \"(b) Filled 2\")\n",
        "im3 = plot2(ax3, filled1 + filled2 - whole, \"(c) Filled 1+2\")\n",
        "\n",
        "# Add a colorbar for each subplot (optional)\n",
        "fig.colorbar(im1, ax=ax1)\n",
        "fig.colorbar(im2, ax=ax2)\n",
        "fig.colorbar(im3, ax=ax3)\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFblwjyi-HNd"
      },
      "outputs": [],
      "source": [
        "# Fill the hole (similar to your Julia code)\n",
        "filled = fill_hole(True, whole, wmask, 20, 2) + fill_hole(False, whole, wmask, 20, 2) - whole\n",
        "\n",
        "# Create the figure and subplots\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# Plot the three images\n",
        "im1 = plot2(ax1, wood, \"(a) Ideal\")\n",
        "im2 = plot2(ax2, whole, \"(b) Gapped\")\n",
        "im3 = plot2(ax3, filled, \"(c) Filled\")\n",
        "\n",
        "# Add a colorbar for each subplot (optional)\n",
        "fig.colorbar(im1, ax=ax1)\n",
        "fig.colorbar(im2, ax=ax2)\n",
        "fig.colorbar(im3, ax=ax3)\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Figure 3 shows a 2D missing data interpolation test using a synthetic pattern from  Claerbout & Brown (1999). The input data for this test is shown in Figure 4b. Interpolation proceeds by running the streaming PEF twice in the forward and backward directions (Figures 3a and 3b) and averaging the interpolation results (Figure 3c.) The cost of such procedure is the cost of two convolutions, as opposed to multiple iterations required in the conventional approach to missing data interpolation with PEFs  (Naghizadeh & Sacchi, 2010; Liu & Fomel, 2011; Claerbout, 2014). A better interpolation result in Figure 4c is achieved by filling the residual inside the gap with small-variance white noise instead of zeros while reconstructing\n",
        "the data from the residual. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "images = []\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "for k in range(1,4):\n",
        "    filled = fill_hole(True,  whole, wmask, 20, 2, k) + fill_hole(False, whole, wmask, 20, 2, k+3) - whole \n",
        "    images.append(plot2(axes[k-1], filled, f\"Realization {k}\"))\n",
        "    fig.colorbar(images[k-1], ax=axes[k-1])\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The random residual approach can generate multiple equiprobable realizations for the missing data interpolation problem in the spirit of geostatistical stochastic simulations (Clapp, 2000). Figure 5 shows three realizations created using different seeds for the pseudorandom number generator. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "-uNOOjYGN_iI"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Create a 128x128 array for the \"herring\" pattern\n",
        "with zipfile.ZipFile(\"files.zip\", \"r\") as zip_ref:\n",
        "    with zip_ref.open(patterns[\"herr\"]) as file:\n",
        "        # Read the file content (for example, as bytes)\n",
        "        data = file.read()\n",
        "        # Convert the data to an appropriate format, if necessary\n",
        "        # For example, you can convert it to a numpy array if it's numerical data\n",
        "        herr = np.frombuffer(data, dtype=np.float32).reshape(128, 128, order=\"F\")\n",
        "\n",
        "# Make a hole in the pattern using the punch_hole function\n",
        "hhole, hmask = punch_hole(herr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JbNrKWKsN_l7"
      },
      "outputs": [],
      "source": [
        "# Fill the hole using forward and backward filling\n",
        "filled = (\n",
        "    fill_hole(True, hhole, hmask, 20, 6) +\n",
        "    fill_hole(False, hhole, hmask, 20, 6) - hhole\n",
        ")\n",
        "\n",
        "# Create the figure and subplots\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# Plot the three images\n",
        "im1 = plot2(ax1, herr, \"(a) Ideal\")\n",
        "im2 = plot2(ax2, hhole, \"(b) Gapped\")\n",
        "im3 = plot2(ax3, filled, \"(c) Filled\")\n",
        "\n",
        "# Add a colorbar for each subplot (optional)\n",
        "fig.colorbar(im1, ax=ax1)\n",
        "fig.colorbar(im2, ax=ax2)\n",
        "fig.colorbar(im3, ax=ax3)\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Figure 6 shows a similar interpolation test applied to 2D data with a non-stationary pattern. Although streaming PEF fails to achieve a perfect reconstruction in this case, it manages to capture most of the pattern and hide the location of the gap."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmMfbdQvN_qA"
      },
      "outputs": [],
      "source": [
        "# \"seismic\" pattern\n",
        "seis_base = np.empty((250, 125), dtype=np.float32, order='F')  # single-precision array\n",
        "\n",
        "# Read the seismic pattern data from the zip file\n",
        "with zipfile.ZipFile(\"files.zip\", \"r\") as zip_ref:\n",
        "    with zip_ref.open(patterns[\"seis\"]) as file:\n",
        "        # Read the file content (assuming it's binary data)\n",
        "        data = file.read()\n",
        "        # Convert the data to a numpy array\n",
        "        seis_base = np.frombuffer(data, dtype=np.float32).reshape((250, 125), order=\"F\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "ekXKocMjN_sX"
      },
      "outputs": [],
      "source": [
        "# Normalize the seismic pattern\n",
        "seis = seis_base.copy()\n",
        "seis = np.asfortranarray(seis_base.copy())\n",
        "m = np.mean(seis_base)\n",
        "seis -= m\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scale = np.std(wood,ddof=1) / np.std(seis,ddof=1)\n",
        "seis *= scale\n",
        "\n",
        "# Make a hole in the seismic pattern\n",
        "shole, smask = punch_hole(seis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKDsHqXrN_uY"
      },
      "outputs": [],
      "source": [
        "# Fill the hole in the seismic pattern\n",
        "filled = fill_hole(True, shole, smask, 20, 0.7) + \\\n",
        "         fill_hole(False, shole, smask, 20, 0.7) - shole\n",
        "\n",
        "# Create the plots\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# Plot the three images\n",
        "im1 = plot2(ax1, seis, \"(a) Ideal\")\n",
        "im2 = plot2(ax2, shole, \"(b) Gapped\")\n",
        "im3 = plot2(ax3, filled, \"(c) Filled\")\n",
        "\n",
        "# Add a colorbar for each subplot (optional)\n",
        "fig.colorbar(im1, ax=ax1)\n",
        "fig.colorbar(im2, ax=ax2)\n",
        "fig.colorbar(im3, ax=ax3)\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Figure 7 shows a similar test applied to 2D seismic data. The pattern made by reflection events with variable slopes is well captured."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "ZoxJsEiniugM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numba import njit\n",
        "\n",
        "@njit\n",
        "def stream_helix_core(na, inv, d, r, hlag, lambd, maxlag, n1):\n",
        "    T = d.dtype\n",
        "    a = np.zeros(na, dtype=T)  # streaming PEF\n",
        "\n",
        "    # Initialize values\n",
        "    for i1 in range(maxlag):\n",
        "        if inv:\n",
        "            d[i1] = r[i1]\n",
        "        else:\n",
        "            r[i1] = d[i1]\n",
        "\n",
        "    da = 0  # d (dot) a\n",
        "    dd = 0  # d (dot) d\n",
        "\n",
        "    for ia in range(na):\n",
        "        dd += d[maxlag + 1 - hlag[ia]] ** 2\n",
        "\n",
        "    sumrn = 0\n",
        "    for i1 in range(maxlag, n1):\n",
        "        if inv:\n",
        "            rn = r[i1] / lambd\n",
        "            dn = rn * (lambd + dd) - da\n",
        "            d[i1] = dn\n",
        "            sumrn += rn\n",
        "        else:\n",
        "            dn = d[i1]\n",
        "            rn = (dn + da) / (lambd + dd)\n",
        "            r[i1] = lambd * rn\n",
        "\n",
        "        # Update PEF\n",
        "        for ia in range(na):\n",
        "            a[ia] -= rn * d[i1 - hlag[ia]]\n",
        "\n",
        "        # Update dd and da\n",
        "        dd += dn * dn - d[i1 - maxlag] * d[i1 - maxlag]\n",
        "        da = dn * a[0]\n",
        "\n",
        "        for ia in range(1, na):\n",
        "            da += a[ia] * d[i1 + 1 - hlag[ia]]\n",
        "\n",
        "def stream_helix(inv, d_n_dim, r_n_dim, lag, lambd):\n",
        "    d = np.reshape(d_n_dim, -1, order='F')\n",
        "    r = np.reshape(r_n_dim, -1, order='F')\n",
        "\n",
        "    n1, na = len(d), len(lag)\n",
        "    hlag = helix(lag, np.array(d_n_dim.shape, order='F'))\n",
        "    maxlag = np.max(hlag)\n",
        "\n",
        "    # Call the JIT-compiled core function\n",
        "    stream_helix_core(na, inv, d, r, hlag, lambd, maxlag, n1)\n",
        "\n",
        "    # Reshape d and r back to their original shapes\n",
        "    d_n_dim = np.reshape(d, d_n_dim.shape, order='F')\n",
        "    r_n_dim = np.reshape(r, r_n_dim.shape, order='F')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "D1CB0c90N_2g"
      },
      "outputs": [],
      "source": [
        "# Apply helix filter\n",
        "pad = np.hstack((np.zeros((seis.shape[0], 20), dtype=np.float32, order=\"F\"), seis))\n",
        "# res = np.empty_like(pad)\n",
        "res = np.zeros_like(pad)\n",
        "\n",
        "# Forward filtering\n",
        "stream_helix(False, pad, res, lag, 1e6)  # pad -> res\n",
        "\n",
        "# Backward filtering\n",
        "stream_helix(True, pad, res, lag, 1e6)   # pad <- res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5R6XI3WVN_75"
      },
      "outputs": [],
      "source": [
        "# Plotting the results\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "im1 = plot2(ax1, seis, \"(a) Input\")\n",
        "im2 = plot2(ax2, 20 * res[:, 20:], \"(b) Residual (x 20)\")\n",
        "im3 = plot2(ax3, pad[:, 20:], \"(c) Inverse\")\n",
        "\n",
        "# Add a colorbar for each subplot (optional)\n",
        "fig.colorbar(im1, ax=ax1)\n",
        "fig.colorbar(im2, ax=ax2)\n",
        "fig.colorbar(im3, ax=ax3)\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this case, removing dominant reflection events by PEF filtering leaves behind weaker hyperbolic diffraction events (Figure 8). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Discussion\n",
        "\n",
        "A streaming application, where the adaptive filter is updated one data point at a time, is appropriate in a continuous stream of large amounts of data, such as in passive monitoring of carbon storage (Alumbaugh et al., 2024). In more typical scenarios, where the data are immediately accessible, more accurate results can be achieved with other forms of regularization, such as regularizing adaptive filter coefficients with smoothing shaping operators (Fomel, 2009; Liu \\& Fomel, 2011; Liu et al., 2012). For greater efficiency, a hybrid regularization strategy can be developed. Such strategies are discussed by Geng et al. (2024), who also extend the streaming approach to other applications of seismic attributes.\n",
        "\n",
        "In applications such as missing data reconstruction, the streaming approach represents an extreme point of the accuracy-efficiency trade-off. To achieve better accuracy, some of the efficiency can be sacrificed at the expense of performing extra iterations. The presented approach is also limited to situations of missing values in regularly sampled data and will need to be modified for situations of irregular data.\n",
        "\n",
        "In multidimensional applications, the helical boundary conditions allow for easy invertibility (Claerbout, 1998) but are not always appropriate. In this case, extra accuracy can also be bought at the cost of sacrificing some of the efficiency.\n",
        "\n",
        "We hope that providing reproducible benchmarks with this paper will invite other researchers to make direct comparisons with more advanced methods. Such comparisons are beyond the scope of this paper because they would require a different codebase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusions\n",
        "\n",
        "We have presented an efficient approach to computing and applying non-stationary prediction-error filters (PEFs). Instead of storing multiple copies of varying filters, the streaming approach stores only one copy and updates the filter on the fly with every new data point. The cost of this procedure is equivalent to the cost of a single convolution and does not require multiple iterations. Moreover, the non-linear operation of estimating and applying a streaming PEF has an exact inverse, which becomes helpful in missing data interpolation\n",
        "problems. A streaming approach to missing data interpolation does not require iterations and can be accomplished effectively at the cost of two convolutions. We anticipate many possible applications of the proposed technique in geophysical estimation problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n",
        "\n",
        "Alumbaugh, D.L., Correa, J., Jordan, P., Petras, B., Chundur, S. and Abriel, W., 2024. An assessment of the role of geophysics in future US geologic carbon storage projects. The Leading Edge, 43, 72-83.\n",
        "\n",
        "Bezanson, J., A. Edelman, S. Karpinski, and V. B. Shah, 2017, Julia: A fresh approach to numerical computing: SIAM Review, 59, 65-98.\n",
        "\n",
        "Claerbout, J., 1998, Multidimensional recursive filters via a helix: Geophysics, 63, 1532–1541.\n",
        "\n",
        "Claerbout, J., and M. Brown, 1999, Two-dimensional textures and prediction-error filters: 61st Mtg., Eur. Assn. Geosci. Eng., Session:1009.\n",
        "\n",
        "Claerbout, J. F., 2014, Geophysical image estimation by example: Environmental soundings image enhancement: Lulu. (http://sep.stanford.edu/sep/prof/).\n",
        "\n",
        "Clapp, R., 2000, Multiple realizations using standard inversion techniques, in SEP-105: Stanford Exploration Project, 67–78.\n",
        "\n",
        "Crawley, S., J. Claerbout, and R. Clapp, 1999, Interpolation with smoothly non-stationary prediction-error filters: 69th Annual International Meeting, SEG, Expanded Abstracts, 1154–1157.\n",
        "\n",
        "Curry, W., 2003, Interpolation of irregularly sampled data with nonstationary, multi- scale prediction-error filters: 73th Annual International Meeting, SEG, Expanded Abstracts, 1913–1916.\n",
        "\n",
        "Fomel, S., 2009, Adaptive multiple subtraction using regularized nonstationary regression: Geophysics, 74, V25–V33.\n",
        "\n",
        "Geng, Z., Fomel, S., Liu, Y., Wang, Q., Zheng, Z. and Chen, Y., 2024. Streaming seismic attributes. Geophysics, 89, A7-A10.\n",
        "\n",
        "Granger, B.E. and F. P\\'{e}rez, F., 2021, Jupyter: Thinking and storytelling with code and data: Computing in Science \\& Engineering, 23, 7-14.\n",
        "\n",
        "Hager, W. W., 1989, Updating the inverse of a matrix: SIAM Review, 31, 221–239. Jeffers, J., and J. Reinders, 2013, Intel Xeon Phi coprocessor high-performance programming: Morgan Kaufmann.\n",
        "\n",
        "Haykin, S., 2002. Adaptive Filter Theory. Prentice-Hall.\n",
        "\n",
        "Liu, G., X. C. J. Du, and K. Wu, 2012, Random noise attenuation using f-x regularized nonstationary autoregression: Geophysics, 77, V61–V69.\n",
        "\n",
        "Liu, Y., and S. Fomel, 2011, Seismic data interpolation beyond aliasing using regularized nonstationary autoregression: Geophysics, 76, V69–V77.\n",
        "\n",
        "Naghizadeh, M., and M. D. Sacchi, 2010, Robust reconstruction of aliased data using autoregressive spectral estimates: Geophysical Prospecting, 58, 1049–1062.\n",
        "\n",
        "Robinson, E. A., and O. M. Osman, eds., 1996, Deconvolution 2: Soc. of Expl. Geophys.\n",
        "\n",
        "Ruan, K., J. Jennings, E. Biondi, R. G. Clapp, S. A. Levin, and J. Claerbout, 2015, Industrial scale high-performance adaptive filtering with PEF applications, in SEP-160: Stanford Exploration Project, 177–188.\n",
        "\n",
        "Sanders, J., and E. Kandrot, 2010, CUDA by example: An introduction to General- Purpose GPU programming: Addison-Wesley Professional.\n",
        "\n",
        "Webster, G. M., ed., 1978, Deconvolution: Soc. of Expl. Geophys.\n",
        "\n",
        "Widrow, B., and S.D. Stearns, Adaptive Signal Processing: Prentice Hall, 1985."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
